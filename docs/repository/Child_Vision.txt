# 最强大模型的视觉能力不如6岁小孩

Published: 2026-01-22
Source: https://mp.weixin.qq.com/s/OUBbiZJFxePebVXKqw07Vw

henry 发自 凹非寺
量子位 | 公众号 QbitAI

谁敢想？

视觉推理这一块，大模型现在还嫩得像个3岁小孩。

来自UniPat AI、xbench、阿里、月之暗面、阶跃星辰等多家研究机构的最新研究显示：

在BabyVision视觉推理benchmark上，当前表现最强的Gemini 3 Pro Preview也只是小胜三岁儿童，跟六岁儿童仍有20%的差距。

图片
与成年人94.1的水平相比，更是天壤之别。

图片
更关键的是，Gemini 3 Pro Preview已经是当前一众模型中的“天花板”。

其他前沿模型，包括GPT-5.2、Claude 4.5 Opus、Grok-4等，整体表现甚至不如三岁小孩。

图片
这一扎心结论，无疑又给当前基于VLA（M）的具身智能泼了盆冷水。

毕竟，一个视觉能力尚未达到三岁儿童水平的AI，很难被指望在真实物理世界中稳定、安全地协助人类。

也正是在这个意义上，BabyVision还给出了另一种视角：

要真正推进多模态智能，未来的模型必须从底层重建视觉能力，而不是继续依赖将视觉问题翻译成语言来“绕行”。

## 视觉推理的语言化瓶颈

在完整的评估中，研究对比了开源和闭源模型的表现：

图片
在闭源模型中： Gemini 3-Pro-Preview以49.7%的得分领跑，随后是GPT-5.2 (34.4%) 和豆包-Seed-1.8 (30.2%)。

其余模型表现则不尽人意：Qwen3-VL-Plus 19.2%，Grok-4 16.2%，Claude-4.5-Opus 14.2%。

在开源模型中，表现最好的是Qwen3VL-235B-Thinking，总分达到22.2%。

其中，Qwen3VL的Thinking版本优于Instruct版本，这表明显示显式推理能减轻视觉不确定性。

此外，即使是最大的开源模型，仍无法与顶尖闭源系统匹敌。

那么，问题来了。

为什么在HLE、IMO等高难度任务中展现出博士级“智商”、甚至能解数学难题的大模型，却会在一些看似简单的“找不同”任务中频频翻车？

先说结论：当前的多模态大模型，通常是在推理前，先将视觉输入转化为语言表征来处理。

这种做法充分利用了大型语言模型强大的推理能力，但也引入了一个根本性的限制：

凡是无法被语言准确表达的视觉信息，都会在这一过程中被丢失。

例如，图像中“一辆红色的汽车”可以被轻松转写为文字；但更细粒度的几何信息，如边界的精确曲率、交叉点的具体位置、相对空间关系的微小变化，却很难被语言忠实描述。

图片
而正是这些“不可描述”的视觉特征，构成了BABYVISION任务的核心难点，也因此成为当前顶尖多模态模型普遍折戟的地方。

具体来说，BabyVision将视觉推理拆解为4个核心能力维度：

细粒度辨别（Fine-grained Discrimination）：检测细微的视觉差异
视觉追踪（Visual Tracking）：追踪路径、线条和运动轨迹
空间感知（Spatial Perception）：理解三维结构与空间关系
视觉模式识别（Visual Pattern Recognition）：识别视觉中的逻辑与几何规律
基于上述能力维度，研究总结出当前MLLM面临的四个经典视觉核心挑战，具体如下：

### 非言语性精细细节的缺失

首先是非言语性精细细节的缺失，这些精细细节往往难以被语言精准地描述。

比如在面对一个小的偏移、特定的边界曲线，或者仅仅是一个像素的差异时，多模态大模型（MLLMs）往往会把这些截然不同的选项当作差不多的来处理。

以表现最好的Gemini 3 Pro Preview为例，在下面的找拼图任务中，它就错误地选择了D选项。

图片
（正确答案：B）

在Gemini的推理过程中，它首先将形状转化为文字描述，再简化为粗略特征（如数量、拓扑结构），然后在语言空间中对比候选选项。

相比之下，人类直接通过形状匹配瞬间完成任务。人类的大脑会对每个候选选项进行平移和旋转，检查边界是否对齐，整个过程无需借道文字，直接由几何驱动。

所以，这里的关键不在于逻辑的难度，而在于高保真感知的缺失。

### 流形一致性（Manifold Identity）的丢失

此外，研究还发现，多模态大模型难以在长距离空间中，可靠地维持感知的一致性。

比如，在下面的连线任务中，Gemini 3 Pro Preview再度失败，错误地将塑料瓶连在了绿色垃圾桶中，以及将苹果核连在了蓝色垃圾桶中，

图片
（正确答案：塑料瓶-蓝、试卷-黄，苹果核-绿）

研究发现，Gemini在解题时，通常会把一条连续的曲线拆解成一连串简单指令，比如向左、向右、向上、向下。

但问题在于，一旦出现交叉点，这种拆解方式就会让路径变得模糊，很容易走岔。

由于模型并没有在脑子里“真正记住”那条曲线的样子，它在经过交叉点后就可能无意中换到另一条线上。

这种错误对人类来说几乎一眼就能看出来，但当信息被压缩成文字后，反而很难察觉。

相比之下，人类一般会直接盯住一条线，一路跟到终点。而这种能力在人类幼儿时期就已经很自然地具备了。

### 空间想象力

研究发现的第三个普遍挑战是“空间想象力”，也就是从二维图像中构建稳定的三维内部表征，并在保持结构不变的前提下，对其进行心理变换——

比如切换视角、投影轮廓，或推断被遮挡的体积。

举例来说：给你一个视图，让你想象如果从侧面看，它应该是什么样子。

在这一任务中，Gemini 3 Pro Preview仍然选择了错误的C选项。

图片
（正确答案：A）

在 Gemini 的推理过程中，模型会先将视觉场景转化为语言摘要，用文字描述物体，再基于这些文字去“猜测”二维特征。

但问题也正出在这里——文字叙述并不能忠实地表示空间状态。

一旦精确的图像被压缩成模糊的文本摘要，模型就很容易犯下可预期的错误：漏掉被遮挡的积木、数错层数，或使用了错误的三维投影关系。

相比之下，人类可以直接在脑海中从指定方向“转动”物体并进行对比，整个过程几乎不需要语言的参与。

### 视觉模式归纳

第四个挑战是视觉模式归纳：也就是从少量视觉示例中，总结出通用的变化规则，并把它应用到新的输入上。

在下面这个找规律的问题中，QWEN3-VL-PLUS选择了错误的B选项。

图片
（正确答案：C）

模型在这类任务中常见的做法，并不是理解“发生了什么变化”，而是去数属性。

比如，颜色有多少、形状有几个、元素是否相似。它会描述源图像、描述目标图像，然后试图在文本层面把两者“对上”。

相较之下，人类在处理这类问题时，通常会直接对比前后的视觉示例，在脑中形成一个简单的“因果图”：

哪个形状包含哪个形状？谁是框架，谁是内容？这些角色在从输入到输出的过程中是如何被重新分配的？

正是这种对视觉关系进行抽象推理的能力——而非简单的识别——构成了当前模型架构仍难以跨越的一道门槛。

## 基于RLVR与生成式建模的视觉推理

那么， 既然基于文本的视觉推理（如 VLM）存在天然局限，那么有没有办法对这一点加以改善？

对此，研究给出了两个方向：基于可验证奖励的强化学习（Reinforcement Learning with Verifiable Rewards ，RLVR)以及基于生成模型的视觉推理。

首先来看RLVR。

具体而言，研究以Qwen3-VL-8B-Thinking作为基座模型，并在其上进行RLVR微调。

图片
实验表明，在完成RLVR微调后，模型整体准确率提升了约4.8个百分点。从任务子类分布来看，大多数类别均出现不同程度的提升。

这和在Qwen推理模型中得到的洞见一致：一旦提取出视觉信号，显式的中间推理可以部分抵消视觉上的不确定性。

接下来是生成模型方法。

既然以语言承载视觉推理存在天然的“信息失真”，模型能否效仿人类，通过“视觉重构”——

即在像素空间内直接演算（如绘制连线或补全图案）来完成推理。

基于这一认识，研究推出了BabyVision-Gen，评估了3种前沿视觉生成模型：NanoBanana-Pro、GPT-Image-1.5和Qwen-Image-Edit在其之上的表现。

（注：BabyVision-Gen从全量基准中筛选出280道适合生成式交互的题目，要求模型直接输出图像或视频流来表达解题过程）

图片
实验结果显示：NanoBanana-Pro表现最优，准确率达18.3%；而GPT-Image-1.5与Qwen-Image-Edit分别为9.8%和4.8%。

虽然成功率仍然不高，但研究认为，NanoBanana-Pro与Sora-2等模型展现出了显式视觉思维，能够沿逻辑路径生成物理轨迹。

图片
此外，在相似的字母中找不同的任务里，基于生成式的方法也表现出了一定的视觉思维能力。

图片
这里的失误也表明：单纯的生成能力并不等同于严密的推理，生成过程还必须由稳健的视觉语义理解（Visual Understanding）进行引导。

图片
由此，研究绕过“语言瓶颈”的统一架构，揭示了一个关键的研究趋势：将生成模型转化为原生多模态推理器。

相比于传统的MLLM强行将视觉信号压缩成文本，像Bagel这样的统一架构，能够在推理过程中保留高保真的视觉表征。

这种架构允许模型在视觉空间内进行“显式思考”——通过勾勒中间步骤、突出关键区域或实时绘制轨迹来解析问题。

同时，像Sora 2和Veo 3等模型在建模物理动力学与空间关系的能力上，进一步支持了“生成本身即是推理的一种高级形式”这一观点。

参考链接

[1]https://unipat.ai/blog/BabyVision

[2]https://arxiv.org/abs/2601.06521v1