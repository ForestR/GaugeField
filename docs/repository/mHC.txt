# DeepSeek 双创新，OCR2 会“读”文档，mHC 改写残差十年规则

Source: https://mp.weixin.qq.com/s/vKFxusFFLty5K97_z3lT0g

**来源**：数据派THU  
**作者**：孙记森 (Datawhale)  
**日期**：2026年2月8日

> **摘要**：本文介绍了 DeepSeek OCR2 模型与 mHC 新思路的核心技术创新。DeepSeek一直带有原创性，总是会给大家一些新的启发和思路。

## 一、DeepSeek-OCR2：从“看”到“读”的进化

昨天 DeepSeek 发布了升级后的 **OCR2** 模型，主要优化是加入模拟人类视觉的“因果推理”机制，把之前的 Clip 模型替换为了大模型架构。

### 1.1 两代 OCR 对比

*   **DeepSeek-OCR1**（2025 年 10 月发布）
    *   **核心贡献**：证明了视觉压缩是解决 LLM 长上下文低效问题的可行且高效路径。
    *   **效果**：实现了“一图胜万言”。实验显示，10 个文本 token 压缩成 1 个视觉 token 时，OCR 精度仍能达到 97%。

*   **DeepSeek-OCR2**（2026 年 1 月 27 日发布）
    *   **核心贡献**：证明了视觉语言模型可以通过“因果流”和动态语义阅读顺序，实现人类级别的文档逻辑理解，从而大幅超越传统固定栅格扫描的局限。

### 1.2 核心架构创新：Visual Causal Flow

OCR2 彻底抛弃了 CLIP 等传统 ViT 骨干，转用 **Qwen2-0.5B** 作为视觉编码器（DeepEncoder V2），并引入 **Visual Causal Flow** 机制：

*   **动态阅读顺序**：模型先全局理解图像布局，再根据语义内容动态决定“先看哪块、再看哪块”。这类似人类阅读报纸时跳过广告、优先读标题、正文、表格的顺序，而非从左上到右下死板扫描。
*   **从 Non-causal 到 Causal**：
    *   **DeepEncoder (旧)**：使用 CLIP ViT，采用双向注意力（Non-causal）。Query A 可以看到 Query B，反之亦然。处理顺序往往是固定的光栅扫描。
    *   **DeepEncoder V2 (新)**：将 CLIP 替换为 LLM 风格的架构（Qwen2 500M），被称为 "LM as Vision Encoder"。强制改为 **Causal（因果/单向注意力）**。即 Query $i$ 只能看到 Query $1 \dots i-1$ 的结果。

这种设计的目的是打破“位置决定顺序”的传统限制，转而实现“**语义决定顺序**”。我们看“哪里”取决于我们刚才看了“什么”。通过因果注意力，迫使模型学会渐进式地整理信息：Query 1 找到第一段话，Query 2 基于 Query 1 的结果去找逻辑上的第二段话（哪怕它在图像的左下角），依此类推。

### 1.3 模型结构详解

整个模型清晰地划分为三个串联的部分：
1.  **视觉分词器**（左侧）
2.  **DeepEncoder V2 (视觉编码器)**（中间）：将无序的 2D 图像特征，转化为有序的、符合人类阅读逻辑的 1D 序列。
3.  **DeepSeek-MoE Decoder (解码器)**（右侧）：不再需要处理复杂的视觉位置关系，只需根据已经排好序的语义信息，通过语言模型生成文本。

**注意力矩阵的特殊设计**：
DeepEncoder V2 注意力矩阵被拼接成了左右两部分：
*   **左侧/上半部分（视觉 Token）**：所有的视觉 Token 之间可以互相“看见”。图像特征保留了传统的 ViT 风格，具备全局感受野，不会因为位置先后而丢失上下文信息。
*   **右侧/下半部分（因果流查询）**：强制模型必须按照生成的先后顺序来建立逻辑依赖。

### 1.4 性能与展望

实验结果证明，DeepSeek-OCR 2 在使用极少视觉 Token（计算成本低）的情况下，依然取得了超越现有开源模型甚至商业闭源模型（如 GPT-4o）的 **SOTA 性能**。

这一架构不仅是 OCR 技术的革新，更是迈向“通用模态编码器”的里程碑。在这一架构下，我们可以预见一个“参数共享”的超级引擎——共享 $W_k, W_v$ 映射和 FFN 层。处理图像、音频或文本时，唯一的变量是特定模态的 Learnable Query。这种设计将不同模态的特征提取与逻辑压缩统一在同一个参数空间内，彻底打破模态间的壁垒。

*   **论文链接**：https://huggingface.co/deepseek-ai/DeepSeek-OCR-2

---

## 二、mHC：改写残差连接十年规则

元旦期间，DeepSeek 提出的 **mHC** (manifold Hyper-Connections) 新思路震撼了全网 AI 社区。

### 2.1 背景：ResNet 与残差连接

回顾何凯明团队提出的 ResNet 残差网络结构：
*   **解决的问题**：深度退化问题。当层数增加到一定程度，训练误差和测试误差反而上升。
*   **关键创新**：残差连接（Residual Connection / Skip Connection）。
    *   传统网络：输出 = $F(x)$
    *   ResNet：输出 = $F(x) + x$
    *   其中 $x$ 是身份映射（identity shortcut），$F(x)$ 是残差函数。如果 $F(x)$ 学到 0，整体就相当于恒等映射，网络至少不会变差。

十年来，“只需增加更多层”的残差连接策略隐含地限制了网络对信息的转换能力。DeepSeek 的贡献是提出重写神经网络的方案：从用于残差的简单加法，转向定义在流形上的几何约束。

### 2.2 从 HC 到 mHC 的演进

*   **普通 Transformer**：残差连接是“单车道”（$F(x) + x$），信号强度基本保持在 1 倍左右，训练稳定。
*   **Hyper-Connections (HC)**：字节跳动提出，想把残差变成“多车道”。一层里同时走好几条并行路径（如 3-4 条），每条路径都加回输入。理论上性能更好，但**无约束的多车道残差会让信号强度指数级爆炸**，导致梯度失控，模型训练崩溃。
*   **mHC (DeepSeek)**：在 HC 的基础上加了一个**流形约束**（用 Sinkhorn-Knopp 算法强制每条路径的权重归一化），确保所有路径加起来的信号强度严格稳定在 $\approx 1.0$ 倍。几乎不损失性能，开销也很小（~7%）。

### 2.3 mHC 具体工作流程

mHC 通过以下三步解决信号爆炸问题并增强语义表达：

**第一步：压缩 (Compression)**
一开始复制四份输入 $X_1$（语义更丰富，分别代表语法、上下文等）。为了降低计算开销，使用一个可学习的向量 $H_{pre}$ ($1 \times n$) 将这 4 个向量合并成 1 个向量。
这实际上是一个加权求和（Weighted Sum）：
$$
X_{compressed} = \sum w_i \cdot X_i
$$

**第二步：加工 (Processing) 与 约束**
将压缩后的这 1 个向量送入标准的 Transformer 层 ($F$) 进行计算（如 Attention 或 Feed-Forward）。
**关键约束**：DeepSeek 强制要求混合矩阵 $H_{res}$ 必须是**双随机矩阵 (Doubly Stochastic Matrix)**。
*   **规则**：每一行加起来必须等于 1，每一列加起来也必须等于 1。
*   **作用**：这保证了无论信息怎么在 4 个通道间传递，总能量（信号强度）保持不变，防止了数值爆炸或消失。

**第三步：扩张 (Expansion)**
计算完成后，得到 1 个新的输出向量。此时使用另一个向量 $H_{post}$ ($1 \times n$) 将其“广播”回 4 个通道。
这不是简单的复制，而是根据权重将新知识以不同比例分配给 4 个通道，从而产生差异化（最终向量包含了语法、上下文、逻辑、领域知识等更多语义信息）。

最后，将“计算路径”产生的新知识，加到“残差路径”混合后的旧记忆上，形成下一层的输入。

### 2.4 结论

DeepSeek 证明了，只要辅以恰当的数学约束（如流形约束），我们可以驯服更复杂的非线性拓扑，从而获得更大的信息容量，建立深度稳定的网络，而无需依赖自 2015 年以来依赖的安全网（简单残差加法）。

也有博主对 mHC 进行了复现，效果比 DeepSeek 原文还要好！

*   **复现博客**：
    *   https://taylorkolasinski.com/notes/mhc-reproduction/
    *   https://taylorkolasinski.com/notes/mhc-reproduction-part2/
*   **mHC 论文**：https://huggingface.co/papers/2512.24880

---
**编辑**：于腾凯  
**校对**：龚力  
**关于我们**：数据派THU作为数据科学类公众号，背靠清华大学大数据研究中心，分享前沿数据科学与大数据技术创新研究动态。